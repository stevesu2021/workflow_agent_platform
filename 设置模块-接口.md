一、核心 AI 服务管理（已有 + 增强）
功能	说明
✅ 文本大模型管理	支持 Qwen、DeepSeek、Llama、ChatGLM、Moonshot、OpenAI 等
• 模型名称 / 别名
• API 地址（兼容 OpenAI 格式或自定义）
• API Key（加密存储）
• 最大上下文长度、temperature 默认值
• 是否启用流式响应
✅ 视觉大模型管理	如 Qwen-VL、GPT-4V、InternVL、CogVLM
• 支持图像输入格式（base64 / URL）
• 最大图像分辨率限制
• 是否启用多轮视觉对话
✅ OCR 服务管理	分为子类型：
• PaddleOCR（本地/远程部署）
• DeepSeek-OCR
• 阿里云 OCR / 百度 OCR（预留）
• 支持批量识别开关、语言类型（中/英/多语）
➕ 向量模型管理	用于 RAG 的 embedding 模型
• BGE、text2vec、OpenAI embeddings
• 维度（768/1024）
• 归一化开关
➕ 重排序模型（Reranker）管理	如 BGE-Reranker、Cohere Rerank
• Top-K 重排数量
• 相似度阈值
二、全局系统配置（平台级）
功能	说明
🌐 默认模型策略	设置平台默认使用的：
• 默认文本模型
• 默认视觉模型
• 默认 OCR 引擎
（用户未指定时自动 fallback）
⏱️ 全局超时设置	所有 AI 请求的统一超时上限（如 60s），可被单个服务覆盖
📦 文件上传限制	图片/文档最大大小、支持格式（PNG/JPG/PDF/TXT）
🌍 多语言支持	系统界面语言（中/英）、OCR 识别语言偏好
🎨 UI 主题配置	亮色/暗色模式、品牌 Logo 上传（适用于私有化部署）
三、安全与权限控制
功能	说明
🔐 API Key 加密存储	后端使用 KMS 或 AES 加密敏感字段，前端仅显示脱敏值（如 sk-abc***xyz）
👥 基于角色的访问控制（RBAC）	
• 管理员：可编辑所有配置
• 开发者：仅查看/测试
• 普通用户：不可见设置模块
📜 操作审计日志	记录：
• 谁在何时修改了哪个模型配置
• 测试连接记录
• 配置导出/导入操作
🚫 IP 白名单（可选）	限制某些 AI 服务仅允许内网调用（防止外泄）
四、运维与可观测性
功能	说明
🔄 服务健康状态面板	实时显示各 AI 服务状态：
• ✅ 正常 / ⚠️ 延迟高 / ❌ 不可用
• 最近一次成功调用时间
📊 调用统计（基础）	按模型/服务统计：
• 日调用量
• 平均响应时间
• 失败率（需后端埋点）
🧪 一键测试连接	对每个服务提供 “Test Connection” 按钮，发送示例请求并返回结果/错误
📤 配置导入/导出	支持 YAML/JSON 格式导出全部 AI 服务配置，便于环境迁移或备份
🔄 配置热更新	修改后无需重启服务，立即生效（需后端支持动态加载）
五、高级扩展能力（面向未来）
功能	说明
🧩 自定义适配器注册	允许用户通过插件方式接入非标准 AI 服务（提供 Webhook 或 SDK 规范）
🌐 多区域部署支持	为同一模型配置多个地域实例（如“北京节点”、“上海节点”），支持负载均衡或就近调用
📝 模型元数据管理	记录模型版本、训练数据截止时间、许可证类型（如商用是否允许）
🤖 智能路由策略	根据输入内容自动选择最优模型（如长文本 → 用 DeepSeek，短问答 → 用 Qwen-Max）
六、用户友好性增强
功能	说明
💡 配置向导（Wizard）	新增服务时提供分步引导（尤其对 PaddleOCR 等复杂部署）
📚 内置文档链接	每个模型类型旁附官方文档或部署指南链接
🛠️ 预设模板	提供常见服务商的预填模板（如“阿里云 DashScope”、“本地 Ollama”）
📱 移动端适配	设置页面在平板/手机上可操作（虽不常用，但提升体验）
总结：设置模块定位升级
从“参数配置页” → 升级为 “AI 能力中枢控制台”

它不仅是填写 URL 的地方，更是：

AI 服务的注册中心
系统稳定性的保障入口
多模型协同的调度基础
安全合规的管控节点
如果你正在开发类似 Dify、LangFlow 或 Coze 的平台，这套扩展后的设置模块将极大提升产品的专业性、可维护性和企业就绪度。

需要我为你生成一个 数据库表结构设计 或 前端 Tab 页面的 React/Vue 组件结构 吗？


代码
|




为设置模块设计前后端用的接口，需要考虑到未来工作流编排阶段，获取每一种类型资源可用的资源列表。
Qwen3-Max
15:29:45
为支持你描述的“设置模块”并兼顾未来工作流编排阶段动态获取可用资源列表的需求，我们需要设计一套统一、可扩展、类型安全的前后端接口。

🎯 设计目标
统一管理所有 AI 资源（文本模型、视觉模型、OCR 服务等）
支持按类型查询可用资源列表（供工作流节点选择）
支持增删改查（CRUD）配置
包含健康状态、是否启用、是否默认等元信息
预留扩展字段，兼容未来新增类型
一、核心数据模型（后端）
AiResource 表（或文档）
字段	类型	必填	说明
id	string (UUID)	✅	资源唯一 ID
name	string	✅	显示名称，如 “Qwen-Max 内网”
type	string	✅	资源类型（见下文枚举）
endpoint	string	✅	服务地址（URL）
api_key	string	❌	敏感字段，加密存储
config	JSON	❌	扩展配置（如 timeout、model_name、lang 等）
is_enabled	boolean	✅	是否启用（禁用后不显示在可用列表）
is_default	boolean	✅	是否为该类型的默认资源
description	string	❌	描述/备注
health_status	enum	✅	unknown / healthy / unhealthy
last_health_check_at	datetime	❌	上次健康检查时间
created_at	datetime	✅	创建时间
updated_at	datetime	✅	更新时间
资源类型枚举（type 字段值）
ts
编辑
// 前端/后端共享常量
enum AiResourceType {
  TEXT_LLM = 'text_llm',           // 文本大模型
  VISION_LLM = 'vision_llm',       // 视觉大模型
  OCR_PADDLE = 'ocr_paddle',       // PaddleOCR
  OCR_DEEPSEEK = 'ocr_deepseek',   // DeepSeek-OCR
  EMBEDDING = 'embedding',         // 向量模型
  RERANKER = 'reranker',           // 重排序模型
  TTS = 'tts',                     // 语音合成（预留）
  STT = 'stt',                     // 语音识别（预留）
}
💡 所有类型使用小写下划线命名，便于扩展。

二、后端 API 接口设计（RESTful）
1. 获取所有可用资源列表（供工作流编排使用）
✅ 关键接口：工作流节点下拉选择时调用

http
编辑
GET /api/v1/ai-resources/available
Query 参数（可选）：

type: string —— 指定类型，如 text_llm，若不传则返回所有类型
响应示例：

json
编辑
{
  "data": [
    {
      "id": "res-001",
      "name": "Qwen-Max (阿里云)",
      "type": "text_llm",
      "is_default": true,
      "description": "支持 32768 上下文"
    },
    {
      "id": "res-002",
      "name": "PaddleOCR 内网服务",
      "type": "ocr_paddle",
      "is_default": false,
      "description": "部署于 192.168.1.100"
    }
  ]
}
⚠️ 注意：只返回 is_enabled: true 的资源，且不返回敏感字段（如 api_key、endpoint）

2. 管理员：获取完整资源配置列表（设置模块使用）
http
编辑
GET /api/v1/ai-resources
响应：返回全部字段（含 endpoint、config 等），用于设置页面编辑。

3. 创建资源
http
编辑
POST /api/v1/ai-resources
请求体：

json
编辑
{
  "name": "DeepSeek-OCR 生产",
  "type": "ocr_deepseek",
  "endpoint": "http://deepseek-ocr.prod:8000/recognize",
  "api_key": "sk-xxx", // 后端加密存储
  "config": {
    "timeout": 15,
    "language": "ch"
  },
  "is_enabled": true,
  "is_default": false,
  "description": "生产环境 OCR 服务"
}
4. 更新资源
http
编辑
PUT /api/v1/ai-resources/{id}
支持部分更新（PATCH 更佳，但 PUT 也可）

5. 删除资源
http
编辑
DELETE /api/v1/ai-resources/{id}
建议：若该资源被工作流引用，应阻止删除或提示“已被使用”

6. 测试连接（健康检查）
http
编辑
POST /api/v1/ai-resources/{id}/test-connection
响应：

json
编辑
{
  "success": true,
  "message": "Connected successfully",
  "latency_ms": 128,
  "sample_response": { ... } // 可选：返回简单识别/生成结果
}
后端执行一次轻量调用（如 OCR 传小图，LLM 传 "hi"），验证可用性

7. 设置默认资源（可选快捷接口）
http
编辑
POST /api/v1/ai-resources/set-default
Body:

json
编辑
{ "type": "text_llm", "resource_id": "res-001" }
自动将同类型其他资源的 is_default 设为 false

三、前端使用场景示例
场景 1：工作流编排 - 选择文本模型
ts
编辑
// 调用
const textModels = await api.get('/ai-resources/available?type=text_llm');

// 渲染下拉框
<Select options={textModels.map(r => ({ label: r.name, value: r.id }))} />
场景 2：设置模块 - 编辑 PaddleOCR 配置
ts
编辑
// 获取完整列表
const allResources = await api.get('/ai-resources');
const paddleResources = allResources.filter(r => r.type === 'ocr_paddle');
四、数据库索引建议（性能优化）
type + is_enabled 联合索引 → 加速 /available 查询
is_default + type 唯一约束 → 确保每种类型最多一个默认
sql
编辑
-- 示例（PostgreSQL）
CREATE INDEX idx_ai_resource_type_enabled ON ai_resources(type, is_enabled);
ALTER TABLE ai_resources ADD CONSTRAINT uniq_default_per_type 
  UNIQUE (type, is_default) 
  WHERE is_default = true;
五、安全与扩展建议
敏感字段加密：api_key 在入库前加密，出库时脱敏
权限控制：/ai-resources 的写操作仅限管理员
Webhook 扩展：未来可支持 type=custom，通过 webhook 调用外部适配器
版本兼容：config 字段为 JSON，可随模型能力演进而扩展
这套接口设计既满足当前设置模块需求，又为工作流编排阶段的资源选择提供了清晰、高效的支撑，同时具备良好的扩展性和安全性。