# conda env vllm
# /home/steve/anaconda3/envs/vllm/bin/python -m vllm.entrypoints.openai.api_server \
#     --model /home/steve/models/Qwen3-Embedding-0.6B/ \
#     --host 0.0.0.0 \
#     --port 8004 \
#     --max-model-len 8192 \
#     --gpu-memory-utilization 0.85 \
#     --served_model_name Qwen3-Embedding-0.6B \
#     --dtype float16 \
#     --max-num-seqs 16 \
#     --enforce-eager



# # conda env vllm
# /home/steve/anaconda3/envs/vllm/bin/python -m vllm.entrypoints.openai.api_server \
#     --model /home/steve/models/Qwen3-Embedding-0.6B/ \
#     --host 0.0.0.0 \
#     --port 8004 \
#     --max-model-len 2048 \          # ğŸ‘ˆ é™ä½æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆembedding ä¸€èˆ¬ä¸éœ€è¦ 8kï¼‰
#     --gpu-memory-utilization 0.6 \   # ğŸ‘ˆ ä» 0.85 â†’ 0.6ï¼Œé¢„ç•™æ›´å¤šæ˜¾å­˜ç¼“å†²
#     --served-model-name Qwen3-Embedding-0.6B \
#     --dtype float16 \
#     --max-num-seqs 4 \              # ğŸ‘ˆ å‡å°‘å¹¶å‘åºåˆ—æ•°ï¼ˆé»˜è®¤ 256 å¤ªé«˜ï¼ï¼‰
#     --enforce-eager \
#     --disable-custom-all-reduce     # ğŸ‘ˆ å•å¡å¯ç¦ç”¨ all-reduce ä¼˜åŒ–ï¼Œçœæ˜¾å­˜


# conda env vllm
#!/bin/bash
# æ–‡ä»¶å: vllm_qwen3_embd.sh

MODEL_DIR="/home/steve/models/"  # ç¡®ä¿è¿™ä¸ªç›®å½•å­˜åœ¨ï¼
MODEL_NAME="Qwen3-Embedding-0.6B"

cd $MODEL_DIR && exec /home/steve/anaconda3/envs/vllm/bin/vllm serve \
    "$MODEL_NAME" \
    --host 0.0.0.0 \
    --port 8004 \
    --max-model-len 2048 \
    --gpu-memory-utilization 0.6 \
    --dtype float16 \
    --max-num-seqs 4 \
    --enforce-eager \
    --disable-custom-all-reduce \
    --runner pooling